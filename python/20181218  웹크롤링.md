# 20181218

## Python

browser.py 파일 하나 더 만들어주기

#### 1. 구글 홈페이지 들어가기

**<편집 창>**

```visual basic
import webbrowser

url = "http://google.com" 
webbrowser.open(url) #브라우저 열어주기
```

<terminal>

```pyth
$ python browser.py
```



#### 2. 키워드 검색해 브라우저 띄우기

**<편집 창>**

```visual basic
import webbrowser

#검색하고 싶은 키워드
q_list = ["이대훈","블랙핑크","정보처리기사","아이유"]

url = "https://www.google.com/search?q="

#브라우저 열어주기
for q in q_list:
    webbrowser.open(url+q) 
```

<terminal>

```pyth
$ python browser.py
```

네개의 창이 다 뜬다.



#### 3. 크롤링위해  request 라이브러리 설치



파일 하나 만들기 crawling.py

**<편집 창>**

```visual basic
import requests

print("Hello")
```

**<terminal>** - requests 라이브러리 설치

```pyth
$ pip install requests
```

**<terminal>** - 다시 실행해보기

```pyth
$ python crawling.py
```

Hello 나옴 



#### 3-2 . 주소 지정해 요청하기

원하는 정보가 있는 주소로 요청을 보내 응답을 저장한다.

**<편집 창>**

```visual basic
import requests

print("Hello")

url = "https://google.com"

#요청하기 : requests.get(url) 
res = requests.get(url)

print(res)
```

<terminal>

```pyth
$ python crawling.py
```

Hello
<Response [200]>

#### 3-3. 주소 요청해 상태만 뽑아오기

#### **<편집 창>**

```visual basic
import requests

print("Hello")

url = "https://google.com"

#요청하기 : requests.get(url) 
#주소에 요청보내서requests 받아줘get 상태만 뽑아줘status_code
res = requests.get(url).status_code

print(res)
```

<terminal>

```pyth
$ python crawling.py
```

Hello
200

####  3-3. 원하는 데이터 뽑아오기  - 다음 실시간 검색어

**<편집 창>**

```visual basic
import requests

print("Hello")

url = "https://www.daum.net/"

#요청하기 : requests.get(url) 
#주소에 요청보내서requests 받아줘get 상태만 뽑아줘status_code
res = requests.get(url).text

print(res)
```

<terminal>

```pyth
$ python crawling.py
```

 다음의 html코드가 나온다

ctrl f 로 찾기 워너원 검색



#### 3-5. 데이터 정제를 위해 bs4 모듈 설치

<terminal>

```pyth
$ pip install bs4
```

**<편집 창>** - bs4중에서도 BeautifulSoup 만 골라서 임포트

```visual basic
from bs4 import BeautifulSoup
```



#### 3-6. 데이터 정제해서 원하는 거 크롤링 : 1위만 



**<편집 창>**

```visual basic
import requests
from bs4 import BeautifulSoup

print("Hello")

url = "https://www.daum.net/"

#요청하기 : requests.get(url) 
#주소에 요청보내서requests 받아줘get 상태만 뽑아줘status_code
res = requests.get(url).text


soup = BeautifulSoup(res,'html.parser')

#다음에서 원하는 구역 태그 
#실시간 검색어 1위 이름 선택 오른쪽 마우스 - 검사 -  블루 부분 
#copy selector  해서 긁어오기 
#코드 안에 child는 bs4가 인식을 못해 type으로 고친다

pick = soup.select('#mArticle > div.cmain_tmp > div.section_media > div.hot_issue.issue_mini > div.hotissue_layer > ol > li:nth-of-type(1) > div > div:nth-of-type(1) > span.txt_issue > a')
print(pick)
```

**<terminal 실행 >**

```pyth
$ python crawling.py
```

**<terminal 결과 >**

```pyth
Hello
[<a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%A1%B0%EC%9E%AC%EB%B2%94&amp;DA=ATG&amp;rtmaxcoll=1TH">조재범</a>]
```



select : 문서안에 있는 특정 내용을 뽑아줘  - 리스트 형태로 반환

 select_one  : 맨 첫번째 요소 하나만 반환



#### 3-7. 데이터 정제해서 원하는 거 크롤링 :  리스트 

**<편집 창>**

```visual basic
import requests
from bs4 import BeautifulSoup

print("Hello")

url = "https://www.daum.net/"

res = requests.get(url).text


soup = BeautifulSoup(res,'html.parser')

#앞의 li~ 는 li만 남겨두고 지운다 : 모든 li를 다 가져오기
#코드 안에 child는 bs4가 인식을 못해 type으로 고친다

pick = soup.select('#mArticle > div.cmain_tmp > div.section_media > div.hotissue_builtin > div.realtime_part > ol > li > div > div:nth-of-type(1) > span.txt_issue > a')
#코드 분석 : 아이디가 Article + 클래스가 cmain_tmp  인거 ~ +  li 목록 가져오기 
print(pick)

 #a 태그에 있는 텍스트만 뽑아오기 
```

**<terminal 실행 >**

```pyth
$ python crawling.py
```

**<terminal 결과 >** -  여러개의 데이터들 나온다. 

```pyth
Hello
[<a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EB%8F%99%EC%84%B1%EC%A0%9C%EC%95%BD&amp;DA=ATG&amp;rtmaxcoll=1TH">동성제약</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%8B%AC%EC%84%9D%ED%9D%AC&amp;DA=ATG&amp;rtmaxcoll=1TH">심석희</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%84%A0%ED%92%8D%EA%B8%B0+%EC%95%84%EC%A4%8C%EB%A7%88&amp;DA=ATG&amp;rtmaxcoll=1TH">선풍기 아줌마</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%9D%B4%ED%95%99%EC%9E%AC+%EC%9D%98%EC%9B%90&amp;DA=ATG&amp;rtmaxcoll=1TH">이학재 의원</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%9D%B4%EC%9A%A9%EB%85%80&amp;DA=ATG&amp;rtmaxcoll=1TH">이용녀</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%95%84%EA%B3%A0%EB%8B%A4&amp;DA=ATG&amp;rtmaxcoll=1TH">아고다</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%ED%95%9C%EA%B3%A0%EC%9D%80&amp;DA=ATG&amp;rtmaxcoll=1TH">한고은</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%86%A1%EC%A4%80%ED%8F%89&amp;DA=ATG&amp;rtmaxcoll=1TH">
송준평</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EC%A1%B0%EC%9E%AC%EB%B2%94&amp;DA=ATG&amp;rtmaxcoll=1TH">조재범</a>, <a class="link_issue" href="https://search.daum.net/search?w=tot&amp;q=%EA%B3%84%EB%A3%A1%EC%84%A0%EB%85%80%EC%A0%84&amp;DA=ATG&amp;rtmaxcoll=1TH">계룡선녀전</a>]
```



#### a 태그에 있는 텍스트만 뽑아오기 

**<편집 창>**

```visual basic

```

**<terminal 실행 >**

```pyth

```

**<terminal 결과 >**

```pyth

```

#### 

#### 4. 빗썸 들고오기

coin.py 파일 만들기

https://www.bithumb.com/ 

f12 마우스 아이콘 - 비트코인 글자  - copy selector

**<편집 창>**

```visual basic
import requests
from bs4 import BeautifulSoup

url = "https://www.bithumb.com/"

#요청 res에 받기 #.text 를 이용해 문서 출력
res = requests.get(url).text

#응답이 들어온 문서를 넣어주고 html문서를 파씽한다.
soup = BeautifulSoup(res, 'html.parser')
coin = soup.select('#tableAsset > tbody > tr:nth-of-type(1) > td:nth-of-type(1) > p > a > strong')
print(coin)
```

**<terminal 실행 >**

```pyth
$ python coin.py
```

**<terminal 결과 >**

```pyth
[<strong>비트코인 </strong>]
```



### 4-1.한가지 요소에 대한 크롤링 말고

#### 원하는 항목 크롤링 해오기 (이름, 가격 등등.. )

f12 - 마우스 - 비트코인만 클릭하지 말고 초록색 요소 선택

**<편집 창>**

```visual basic
import requests
from bs4 import BeautifulSoup

url = "https://www.bithumb.com/"


res = requests.get(url).text

soup = BeautifulSoup(res, 'html.parser')

# #coinlist 중에서 tbody요소만 찾아올래
# coin = soup.select('tbody.coin_list')

#coinlist 중에서 tbody요소만 찾아올래 + tr만 가져올래
coins = soup.select('tbody.coin_list tr')

#반복문 돌려 출력 : 한줄이 하나씩 출력 
#텍스트 형식으로 첫번째 항목(이름) 텍스트 형식으로 출력 : td:nth-of-type(1) a strong
#두번째 항목 (가격): td:nth-of-type(2)  strong
for coin in coins:
    print(coin.select_one ("td:nth-of-type(1) a strong").text) #a태그 안에 strong
    print(coin.select_one ("td:nth-of-type(2)  strong").text) 
    print("-------")

```

**<terminal 실행 >**

```pyth
$ python coin.py
```

**<terminal 결과 >**

```py
비트코인
3,926,000원
-------
이더리움
104,800원
-------
대시
77,900원
-------
라이트코인
32,310원
-------
이더리움 클래식
4,425원
-------
리플
370원
-------
비트코인 캐시
98,900원
-------
모네로0.
48,800원
-------
제트캐시
61,650원
-------
퀀텀
2,245원
-------
비트코인 골드
13,650원
-------
이오스
2,677원
-------
아이콘
234원
-------
비체인
6.63원
-------
트론
15.70원
-------
엘프
120원
-------
미스릴
76.60원
-------
크립토닷컴
2,094원
-------
오미세고
1,402원
-------
카이버 네트워크
147원
-------
골렘
67.30원
-------
질리카
15.80원
-------
에토스
629원
-------
텐엑스
941원
-------
왁스
79.10원
-------
파워렛저
225원
-------
루프링
254원
-------
기프토
60.10원
-------
스팀
1,259원
-------
스트라티스
1,454원
-------
제로엑스
326원
-------
어거
33,650원
-------
애터니티
918원
-------
넴
72.00원
-------
스테이터스네트워크토큰
107원
-------
에이다
60.10원
-------
파퓰러스
1,400원
-------
코르텍스
115원
-------
사이버마일즈
30.80원
-------
쎄타토큰
49.30원
-------
월튼체인
1,140원
-------
아이오티체인
141원
-------
트루체인
269원
-------
아크블록
77.60원
-------
원루트 네트워크
64.20원
-------
플레이코인
34.00원
-------
웨이브
2,787원
-------
체인링크
264원
-------
엔진코인
36.60원
-------
프리마스
106원
-------
솔트
230원
-------
레이든네트워크토큰
194원
-------
룸네트워크
46.20원
-------
비에이치피캐시
618원
-------
피벡스
574원
-------
아이앤에스
254원
-------
비트코인 다이아몬드
830원
-------
베잔트
27.60원
-------
스텔라루멘
122원
-------
오디세이
2.78원
-------
비트코인에스브이
88,900원
-------
더마이다스터치골드
10.30원
-------
베이직어텐션토큰
149원
-------
위쇼토큰
15.20원
-------
버지
6.86원
-------
이오스트 NEW
4.86원
-------
폴리매스 NEW
160원
-------
하이퍼캐시
1,171원
-------
```

#### 4-2.환율 사이트 크롤링

https://spib.wooribank.com/pib/Dream?withyou=CMCOM0184



**<편집 창>**

```visual basic
import requests
from bs4 import BeautifulSoup

url = "http://m.exchange.daum.net/mobile/exchange/exchangeMain.daum"

res = requests.get(url).text
soup = BeautifulSoup(res,'html.parser')

kbos = soup.select('#asiaBody tr.link')

for kbo in kbos:
    print((kbo.select_one("td.name a").text)+(kbo.select_one("td.idx").text))
    print("----")

print("bye")    

```

**<terminal 실행 >**

```pyth
$ python kbo.py
```

**<terminal 결과 >**

```pyth
일본 JPY1001,004.67
----
중국 CNY163.97
----
뉴질랜드 NZD774.74
----
홍콩 HKD144.64
----
인도 INR15.85
----
말레이지아 MYR270.64
----
방글라데시 BDT13.48
----
파키스탄 PKR8.08
----
인도네시아 IDR1007.82
----
대만 TWD36.69
----
필리핀 PHP21.35
----
호주 AUD812.73
----
싱가포르 SGD824.32
----
태국 THB34.52
----
브루나이 BND824.32
----
베트남 VND1004.85
----
몽골 MNT0.43
----
카자흐스탄 KZT3.05
----
bye
```

#### 4-2.melon 사이트 랭크100 크롤링

**<편집 창>**

```visual basic
import requests
from bs4 import BeautifulSoup

url = "https://www.melon.com/chart/index.htm"
headers = {
    'User-Agent': 'My User Agent 1.0',
    'From': 'youremail@domain.com'  # This is another valid field
}
response = requests.get(url, headers=headers).text
soup = BeautifulSoup(response,'html.parser')
music_table = soup.select("table tr.lst50") #리스트 

for music in music_table:
    number = music.select_one("span.rank").text #랭크에 대한 정보
    title = music.select_one("div.wrap_song_info a").text #제목에 대한 정보 
    title = music.select_one("div.rank01 a").text #제목에 대한 정보 
    print(number +"위 : "+ title)

```

**<terminal 실행 >**

```pyth
$ python melon.py
```

**<terminal 결과 >**

```pyth
1위 : 180도
2위 : 아낙네
3위 : Love Shot
4위 : SOLO
5위 : Tempo
6위 : 너를 만나
7위 : 트라우마 (Trauma)
8위 : 봄바람
9위 : YES or YES
10위 : 첫눈에
11위 : Wait
12위 : Gravity
13위 : 닿은 순간 (Ooh La La La)
14위 : 24/7
15위 : Sign
16위 : 여기 있을게 (Smile On My Face)
17위 : 가끔 (With You)
18위 : 신용재
19위 : Damage
20위 : 후폭풍 (Bad Dream)
21위 : Universe
22위 : 오아시스 (Oasis)
23위 : 가을 타나 봐
24위 : 아름답고도 아프구나
25위 : 내 생에 아름다운
26위 : 삐삐
27위 : 모든 날, 모든 순간 (Every day, Every Moment)
28위 : 동화 (feat. 아이유)
29위 : 고백
30위 : 에너제틱 (Energetic)
31위 : Beautiful
32위 : 하루도 그대를 사랑하지 않은 적이 없었다
33위 : 집
34위 : BOOMERANG (부메랑)
35위 : 이번 겨울
36위 : 켜줘 (Light)
37위 : 술래
38위 : 불꽃놀이 (Flowerbomb)
39위 : thank u, next
40위 : 흔한 이별
41위 : 이별하러 가는 길
42위 : IDOL
43위 : 묻고싶다 (One Love)
44위 : 소나무
45위 : Beautiful (Part ll)
46위 : 열애중
47위 : Deeper
48위 : 약속해요 (I.P.U.)
49위 : Awake!
50위 : Way Back Home
```



### 5-1.

ssafy 지원자 파일 사용 

이 파일을 c/users/student/change 에 두기



문제: 지원자 파일명 앞에  SAMSUNG을 다 붙여서 제출하기

changename.py 만들기

**<편집 창>**

```visual basic
import os

#작업하고 있는 위치 변경
os.chdir(r'C:\Users\student\change\SSAFY지원자')

#지정된 디렉토리 전체 파일 목록 얻기
for filename in os.listdir("."):
    #(원래이름,바꿀이름)
    os.rename(filename,"SAMSUNG_"+filename)
    
```

**<terminal 실행 >**

```pyth
$ python changename.py
```

**<terminal 결과 >**

```pyth

```



SAMSUNG을 지우고  SSAFY 붙이기**<편집 창>**

```visual basic
import os
import glob

#작업하고 있는 위치 변경
#r: 날것의 (윈도우 url구조를 원시 구조로 바꿔주는 코드)
os.chdir(r'C:\Users\student\change\SSAFY지원자')

# #지정된 디렉토리 전체 파일 목록 얻기
# for filename in os.listdir("."):
#     print(filename)
#     #(원래이름,바꿀이름)
#     os.rename(filename,"SAMSUNG_"+filename)

for filename in os.listdir("."):
    after_name = filename.replace('SAMSUNG_SSAFY_','SSAFY_')
    os.rename(filename,after_name)
   

   #010.9689.0525
```

**<terminal 실행 >**

```pyth
$ python changename.py
```

**<terminal 결과 >**

폴더 들어가면 수정되어 있음.
